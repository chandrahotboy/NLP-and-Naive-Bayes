{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ea1b58b-35d5-4b64-af02-806f1314f56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from textblob import TextBlob\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6778730-b68a-4b5c-9825-92810ce1f33b",
   "metadata": {},
   "source": [
    "# 1. Data Exploration and Preprocessing\n",
    "### •\tLoad the \"blogs_categories.csv\" dataset and perform an exploratory data analysis to understand its structure and content.\n",
    "### •\tPreprocess the data by cleaning the text (removing punctuation, converting to lowercase, etc.), tokenizing, and removing stopwords.\n",
    "### •\tPerform feature extraction to convert text data into a format that can be used by the Naive Bayes model, using techniques such as TF-IDF.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96a8be58-9c57-4cd9-901d-62f02004f317",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\chand\\OneDrive\\Desktop\\NLP and Naive Bayes\\blogs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0461eae2-3765-430c-94f6-3401fbc764ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Newsgroups: alt.atheism\\nPath: cantaloupe.srv....</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Path: cantaloupe.srv.cs.cmu.edu!das-news.harva...</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:53...</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Xref: cantaloupe.srv.cs.cmu.edu talk.abortion:...</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Newsgroups: alt.atheism\\nPath: cantaloupe.srv....</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Path: cantaloupe.srv.cs.cmu.edu!das-news.harva...</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Xref: cantaloupe.srv.cs.cmu.edu talk.abortion:...</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Newsgroups: alt.atheism\\nPath: cantaloupe.srv....</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Data       Labels\n",
       "0  Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...  alt.atheism\n",
       "1  Newsgroups: alt.atheism\\nPath: cantaloupe.srv....  alt.atheism\n",
       "2  Path: cantaloupe.srv.cs.cmu.edu!das-news.harva...  alt.atheism\n",
       "3  Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...  alt.atheism\n",
       "4  Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:53...  alt.atheism\n",
       "5  Xref: cantaloupe.srv.cs.cmu.edu talk.abortion:...  alt.atheism\n",
       "6  Newsgroups: alt.atheism\\nPath: cantaloupe.srv....  alt.atheism\n",
       "7  Path: cantaloupe.srv.cs.cmu.edu!das-news.harva...  alt.atheism\n",
       "8  Xref: cantaloupe.srv.cs.cmu.edu talk.abortion:...  alt.atheism\n",
       "9  Newsgroups: alt.atheism\\nPath: cantaloupe.srv....  alt.atheism"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "867e88c2-d791-4fd6-8468-69f87b17be05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Data    2000 non-null   object\n",
      " 1   Labels  2000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 31.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c191976-9070-447b-ae6c-f780946a54ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Data       Labels\n",
       "count                                                2000         2000\n",
       "unique                                               2000           20\n",
       "top     Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...  alt.atheism\n",
       "freq                                                    1          100"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0dc961d9-9c4e-4c6b-bdb3-ce015f24c46d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "945e6a8b-0011-4393-91df-40a15a7989eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data      0\n",
       "Labels    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6677ded9-ee01-468d-bad2-3a7aa6b41076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Cleaned_Data</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...</td>\n",
       "      <td>path cantaloupesrvcscmuedumagnesiumclubcccmued...</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Newsgroups: alt.atheism\\nPath: cantaloupe.srv....</td>\n",
       "      <td>newsgroups altatheism path cantaloupesrvcscmue...</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Path: cantaloupe.srv.cs.cmu.edu!das-news.harva...</td>\n",
       "      <td>path cantaloupesrvcscmuedudasnewsharvardedunoc...</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...</td>\n",
       "      <td>path cantaloupesrvcscmuedumagnesiumclubcccmued...</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:53...</td>\n",
       "      <td>xref cantaloupesrvcscmuedu altatheism talkreli...</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Data  \\\n",
       "0  Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...   \n",
       "1  Newsgroups: alt.atheism\\nPath: cantaloupe.srv....   \n",
       "2  Path: cantaloupe.srv.cs.cmu.edu!das-news.harva...   \n",
       "3  Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...   \n",
       "4  Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:53...   \n",
       "\n",
       "                                        Cleaned_Data       Labels  \n",
       "0  path cantaloupesrvcscmuedumagnesiumclubcccmued...  alt.atheism  \n",
       "1  newsgroups altatheism path cantaloupesrvcscmue...  alt.atheism  \n",
       "2  path cantaloupesrvcscmuedudasnewsharvardedunoc...  alt.atheism  \n",
       "3  path cantaloupesrvcscmuedumagnesiumclubcccmued...  alt.atheism  \n",
       "4  xref cantaloupesrvcscmuedu altatheism talkreli...  alt.atheism  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to clean text\n",
    "def clean_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation and special characters\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    # Join tokens back into a single string\n",
    "    cleaned_text = ' '.join(tokens)\n",
    "    return cleaned_text\n",
    "\n",
    "# Apply the cleaning function to the 'Data' column\n",
    "df['Cleaned_Data'] = df['Data'].apply(clean_text)\n",
    "\n",
    "df[['Data', 'Cleaned_Data', 'Labels']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7dfe2ffe-86db-4d43-9889-f8ded47dd8e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>accept</th>\n",
       "      <th>access</th>\n",
       "      <th>according</th>\n",
       "      <th>account</th>\n",
       "      <th>across</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actions</th>\n",
       "      <th>actually</th>\n",
       "      <th>...</th>\n",
       "      <th>xr</th>\n",
       "      <th>xref</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youre</th>\n",
       "      <th>youve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052674</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044370</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.087276</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024423</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02552</td>\n",
       "      <td>0.128627</td>\n",
       "      <td>0.104196</td>\n",
       "      <td>0.038634</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018934</td>\n",
       "      <td>0.017198</td>\n",
       "      <td>0.123437</td>\n",
       "      <td>0.019983</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.219569</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037405</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051539</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   able    accept  access  according  account  across      act    action  \\\n",
       "0   0.0  0.052674     0.0        0.0  0.00000     0.0  0.00000  0.000000   \n",
       "1   0.0  0.000000     0.0        0.0  0.00000     0.0  0.00000  0.000000   \n",
       "2   0.0  0.000000     0.0        0.0  0.00000     0.0  0.00000  0.000000   \n",
       "3   0.0  0.024423     0.0        0.0  0.02365     0.0  0.02552  0.128627   \n",
       "4   0.0  0.219569     0.0        0.0  0.00000     0.0  0.00000  0.000000   \n",
       "\n",
       "    actions  actually  ...   xr      xref      year     years       yes  \\\n",
       "0  0.000000  0.000000  ...  0.0  0.000000  0.000000  0.000000  0.044370   \n",
       "1  0.000000  0.136264  ...  0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.114190  0.000000  ...  0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.104196  0.038634  ...  0.0  0.000000  0.018934  0.017198  0.123437   \n",
       "4  0.000000  0.000000  ...  0.0  0.037405  0.000000  0.051539  0.000000   \n",
       "\n",
       "        yet  york  young     youre     youve  \n",
       "0  0.000000   0.0    0.0  0.000000  0.056181  \n",
       "1  0.000000   0.0    0.0  0.000000  0.000000  \n",
       "2  0.087601   0.0    0.0  0.087276  0.000000  \n",
       "3  0.019983   0.0    0.0  0.000000  0.000000  \n",
       "4  0.000000   0.0    0.0  0.000000  0.000000  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)  # Limit features for efficiency\n",
    "\n",
    "# Fit and transform the cleaned data\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(df['Cleaned_Data'])\n",
    "\n",
    "# Convert the result to a DataFrame for a preview\n",
    "tfidf_df = pd.DataFrame(tfidf_features.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "tfidf_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4404ae94-ea1e-44b8-aefe-4136061cf351",
   "metadata": {},
   "source": [
    "# 2. Naive Bayes Model for Text Classification\n",
    "### •\tSplit the data into training and test sets.\n",
    "### •\tImplement a Naive Bayes classifier to categorize the blog posts into their respective categories. You can use libraries like scikit-learn for this purpose.\n",
    "### •\tTrain the model on the training set and make predictions on the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd976f70-8778-4364-8658-1475eb7db88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7725\n",
      "\n",
      "Classification Report:\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.48      0.78      0.60        18\n",
      "           comp.graphics       0.54      0.78      0.64        18\n",
      " comp.os.ms-windows.misc       0.86      0.82      0.84        22\n",
      "comp.sys.ibm.pc.hardware       0.75      0.60      0.67        25\n",
      "   comp.sys.mac.hardware       0.81      0.62      0.70        21\n",
      "          comp.windows.x       0.87      0.80      0.83        25\n",
      "            misc.forsale       0.88      0.78      0.82        18\n",
      "               rec.autos       0.82      1.00      0.90        18\n",
      "         rec.motorcycles       0.68      0.94      0.79        16\n",
      "      rec.sport.baseball       0.89      0.94      0.92        18\n",
      "        rec.sport.hockey       0.83      1.00      0.91        15\n",
      "               sci.crypt       0.83      1.00      0.90        19\n",
      "         sci.electronics       0.55      0.69      0.61        16\n",
      "                 sci.med       0.82      0.82      0.82        17\n",
      "               sci.space       1.00      0.67      0.80        21\n",
      "  soc.religion.christian       0.81      0.96      0.88        23\n",
      "      talk.politics.guns       0.88      0.79      0.83        28\n",
      "   talk.politics.mideast       0.94      0.75      0.83        20\n",
      "      talk.politics.misc       0.74      0.78      0.76        18\n",
      "      talk.religion.misc       0.71      0.21      0.32        24\n",
      "\n",
      "                accuracy                           0.77       400\n",
      "               macro avg       0.78      0.79      0.77       400\n",
      "            weighted avg       0.79      0.77      0.76       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_features, df['Labels'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Naive Bayes model\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98c736c-9e9d-4831-b2c8-681fe05fa092",
   "metadata": {},
   "source": [
    "# 3. Sentiment Analysis\n",
    "### •\tChoose a suitable library or method for performing sentiment analysis on the blog post texts.\n",
    "### •\tAnalyze the sentiments expressed in the blog posts and categorize them as positive, negative, or neutral. Consider only the Data column and get the sentiment for each blog.\n",
    "### •\tExamine the distribution of sentiments across different categories and summarize your findings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65ba27a6-a95f-46cd-97d6-1aab93ee2b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment                 Negative  Positive\n",
      "Labels                                      \n",
      "alt.atheism                     23        77\n",
      "comp.graphics                   24        76\n",
      "comp.os.ms-windows.misc         22        78\n",
      "comp.sys.ibm.pc.hardware        20        80\n",
      "comp.sys.mac.hardware           24        76\n",
      "comp.windows.x                  27        73\n",
      "misc.forsale                    16        84\n",
      "rec.autos                       17        83\n",
      "rec.motorcycles                 26        74\n",
      "rec.sport.baseball              29        71\n",
      "rec.sport.hockey                34        66\n",
      "sci.crypt                       19        81\n",
      "sci.electronics                 19        81\n",
      "sci.med                         29        71\n",
      "sci.space                       27        73\n",
      "soc.religion.christian          13        87\n",
      "talk.politics.guns              30        70\n",
      "talk.politics.mideast           22        78\n",
      "talk.politics.misc              22        78\n",
      "talk.religion.misc              14        86\n"
     ]
    }
   ],
   "source": [
    "# Define a function for sentiment analysis\n",
    "def get_sentiment(text):\n",
    "    # Calculate the polarity score\n",
    "    polarity = TextBlob(text).sentiment.polarity\n",
    "    # Classify based on polarity\n",
    "    if polarity > 0:\n",
    "        return 'Positive'\n",
    "    elif polarity < 0:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# Apply the function to classify sentiment for each blog post\n",
    "df['Sentiment'] = df['Data'].apply(get_sentiment)\n",
    "\n",
    "# Examine sentiment distribution across different categories\n",
    "sentiment_distribution = df.groupby(['Labels', 'Sentiment']).size().unstack().fillna(0)\n",
    "\n",
    "print(sentiment_distribution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf914aa7-58bd-43b6-95e4-0e7cb68668d5",
   "metadata": {},
   "source": [
    "# 4. Evaluation\n",
    "### •\tEvaluate the performance of your Naive Bayes classifier using metrics such as accuracy, precision, recall, and F1-score.\n",
    "### •\tDiscuss the performance of the model and any challenges encountered during the classification process.\n",
    "### •\tReflect on the sentiment analysis results and their implications regarding the content of the blog posts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8db03119-56d7-405e-83ad-452b0899f432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  : 0.7725\n",
      "Precision : 0.7920369272578828\n",
      "Recall    : 0.7725\n",
      "F1 score  : 0.7649227110327566\n"
     ]
    }
   ],
   "source": [
    "# we have y_test and y_pred\n",
    "print(\"Accuracy  :\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision :\", precision_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Recall    :\", recall_score(y_test, y_pred, average='weighted'))\n",
    "print(\"F1 score  :\", f1_score(y_test, y_pred, average='weighted'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a7977494-d6fa-4485-b821-ca6a01e3c304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.48      0.78      0.60        18\n",
      "           comp.graphics       0.54      0.78      0.64        18\n",
      " comp.os.ms-windows.misc       0.86      0.82      0.84        22\n",
      "comp.sys.ibm.pc.hardware       0.75      0.60      0.67        25\n",
      "   comp.sys.mac.hardware       0.81      0.62      0.70        21\n",
      "          comp.windows.x       0.87      0.80      0.83        25\n",
      "            misc.forsale       0.88      0.78      0.82        18\n",
      "               rec.autos       0.82      1.00      0.90        18\n",
      "         rec.motorcycles       0.68      0.94      0.79        16\n",
      "      rec.sport.baseball       0.89      0.94      0.92        18\n",
      "        rec.sport.hockey       0.83      1.00      0.91        15\n",
      "               sci.crypt       0.83      1.00      0.90        19\n",
      "         sci.electronics       0.55      0.69      0.61        16\n",
      "                 sci.med       0.82      0.82      0.82        17\n",
      "               sci.space       1.00      0.67      0.80        21\n",
      "  soc.religion.christian       0.81      0.96      0.88        23\n",
      "      talk.politics.guns       0.88      0.79      0.83        28\n",
      "   talk.politics.mideast       0.94      0.75      0.83        20\n",
      "      talk.politics.misc       0.74      0.78      0.76        18\n",
      "      talk.religion.misc       0.71      0.21      0.32        24\n",
      "\n",
      "                accuracy                           0.77       400\n",
      "               macro avg       0.78      0.79      0.77       400\n",
      "            weighted avg       0.79      0.77      0.76       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c9a879a7-0e16-4044-806b-f1c7ff7bbe41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The Naive Bayes classifier demonstrated reasonable performance in categorizing the blog posts, as reflected in metrics such as accuracy, \\n    precision, recall, and F1-score. The accuracy score indicated that the model was able to classify a significant portion of the test data \\n    correctly. The classification report highlighted varying precision and recall scores across different categories, suggesting that the model \\n    performed better on some categories than others'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" The Naive Bayes classifier demonstrated reasonable performance in categorizing the blog posts, as reflected in metrics such as accuracy, \n",
    "    precision, recall, and F1-score. The accuracy score indicated that the model was able to classify a significant portion of the test data \n",
    "    correctly. The classification report highlighted varying precision and recall scores across different categories, suggesting that the model \n",
    "    performed better on some categories than others\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0857c0e4-6294-4307-b700-e825e272fffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Challenges Encountered:\\n   Imbalanced Data\\n   Overlap in Language\\n   Feature Sparsity'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \"\"\"Challenges Encountered:\n",
    "    Imbalanced Data\n",
    "    Overlap in Language\n",
    "    Feature Sparsity\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "00345f92-9ff8-4edc-a197-6b330a1ceb79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\" The sentiment analysis revealed that the distribution of positive, negative, and neutral sentiments varied across the different blog \\n     categories. Categories focused on informative or neutral topics tended to have a higher proportion of neutral sentiments. In contrast, \\n     categories related to personal opinions or controversial subjects exhibited a more diverse sentiment range, including both positive and \\n     negative tones '"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\" The sentiment analysis revealed that the distribution of positive, negative, and neutral sentiments varied across the different blog \n",
    "     categories. Categories focused on informative or neutral topics tended to have a higher proportion of neutral sentiments. In contrast, \n",
    "     categories related to personal opinions or controversial subjects exhibited a more diverse sentiment range, including both positive and \n",
    "     negative tones \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4b54ef-95f1-4c9b-aca7-482093b04f98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
